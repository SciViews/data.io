% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read.R
\name{read}
\alias{read}
\alias{type_from_extension}
\alias{hread_text}
\alias{hread_xls}
\alias{hread_xlsx}
\alias{$.subsettable_type}
\alias{.DollarNames.read_function_subset}
\title{Read data in \R in different formats}
\usage{
read(
  file,
  type = NULL,
  header = "#",
  header.max = 50L,
  skip = 0L,
  locale = default_locale(),
  lang = getOption("data.io_lang", "en"),
  lang_encoding = "UTF-8",
  as_dataframe = FALSE,
  as_labelled = FALSE,
  comments = NULL,
  package = NULL,
  sidecar_file = TRUE,
  fun_list = NULL,
  hfun = NULL,
  fun = NULL,
  data,
  cache_file = NULL,
  method = "auto",
  quiet = FALSE,
  ...
)

type_from_extension(file, full = FALSE)

hread_text(file, header.max, skip = 0L, locale = default_locale(), ...)

hread_xls(file, header.max, skip = 0L, locale = default_locale(), ...)

hread_xlsx(file, header.max, skip = 0L, locale = default_locale(), ...)

\method{$}{subsettable_type}(x, name)

\method{.DollarNames}{read_function_subset}(x, pattern = "")
}
\arguments{
\item{file}{The path to the file to read, or the name of the dataset to get
from an \R package (in that case, you \strong{must} provide the \verb{package=}
argument).}

\item{type}{The type (format) of data to read.}

\item{header}{The character to use for the header and other comments.}

\item{header.max}{The maximum of lines to consider for the header.}

\item{skip}{The number of lines to skip at the beginning of the file.}

\item{locale}{A readr locale object with all the data regarding required to
correctly interpret country-related items. The default value matches R
defaults as US English + UTF-8 encoding, and it is advised to be used as
much as possible.}

\item{lang}{The language to use (mainly for comment, label and units), but
also for factor levels or other character strings if a translation exists
and if the language is spelled with uppercase characters (e.g., \code{"FR"}).
The default value can be set with, e.g., \code{options(data.io_lang = "fr")} for
French.}

\item{lang_encoding}{Encoding used by R scripts for translation. They should
all be encoded as \code{UTF-8}, which is the default. However, this argument
allows to specify a different encoding if needed.}

\item{as_dataframe}{Deprecated: now use \code{options(SciViews.as_dtx = as_XXX)}
to specify if you want a data.frame (\code{as_dtf}), a data.table (\code{as_dtt}, by
default), or a tibble (\code{as_dtbl}).  Do we try to convert the resulting
object into a \code{dataframe} (inheriting from \code{data.frame}, \code{tbl} and \code{tbl_db}
alias \code{tibble})? If \code{FALSE}, no conversion is attempted. Note that now,
whatever you indicate, it is always assumed to be \code{FALSE} as part of the
deprecation!}

\item{as_labelled}{Are variable converted into 'labelled' objects. This
allows to keep labels and units when the vector is manipulated, but it can
lead to incompatibilities with some R code (hence, it is \code{FALSE} by default).}

\item{comments}{Comments to add in the created object.}

\item{package}{The package where to look for the dataset. If \verb{file=} is not
provided, a list of available datasets in the package is displayed.}

\item{sidecar_file}{If \code{TRUE} and a file with same name as \verb{file=} + \code{.R} is
found in the same directory, it is considered as code to import these data
and it is sourced with \code{local = TRUE}, \code{chdir = TRUE} and
\code{verbose = FALSE}. That script \strong{must} create an object named \code{dataset},
which is the result that is returned by the function. It is advised to
encode this script in \code{UTF-8}, which is the default value, but it is
possible to specify a different encoding through the \verb{lang_encoding=}
parameter.}

\item{fun_list}{The table with correspondence of the types, read, and write
functions.}

\item{hfun}{The function to read the header (lines starting with a special
mark, usually '#' at the beginning of the file). This function must have
the same arguments as \code{hread_text()} and should return a character string
with the first \code{header.max} lines.}

\item{fun}{The function to delegate reading of the data. If \code{NULL} (default),
The function is chosen from \code{fun_list}.}

\item{data}{A synonym to \verb{file=} (the name makes more sense when the dataset
is loaded from a package). You cannot use \verb{data=} and \verb{file=} at the same
time.}

\item{cache_file}{The path to a local file to use as a cache when file is
downloaded (http://, https://, ftp://, or file:// protocols). If cache_file
already exists, data are read from this cache. Otherwise, data are saved in
it before being used. If \code{cache_file = NULL} (the default), a temporary
file is used and data are read from the Internet every time. The function
also check if a sidecar file can be downloaded if \code{sidecar_file = TRUE},
and the same cache mechanism is used for this second file too (same URL
than the main file + \code{.R}). This cache mechanism is particularly useful to
provide data associated with a git repository. Put cache_file in
\code{.gitignore} and use \verb{cache_file=} in the code. That way, the data are
downloaded once in a freshly cloned repository, and they are \strong{not}
included in the versioning system (useful for large datasets).}

\item{method}{The downloading method used (\code{"auto"} by default), see
\code{\link[utils:download.file]{utils::download.file()}}.}

\item{quiet}{In case we have to download files, do it silently (\code{TRUE}) or
do we provide feedback and a progression bar (\code{FALSE}, by default)?}

\item{...}{Further arguments passed to the function \verb{fun=}.}

\item{full}{Do we retrun the full extension, like \code{csv.tar.gz} (\code{TRUE}), or
only the main extension, like \code{csv} (\code{FALSE}, by default).}

\item{x}{A \code{subsettable_type} function.}

\item{name}{The value to use for the \verb{type=} argument.}

\item{pattern}{A regular expression to list matching names.}
}
\value{
An \R object with the data (its class depends on the data being read).
}
\description{
Read and return an \R object from data on disk, from URL, or
from packages.
}
\details{
\code{read()} allows for a unique entry point to read various kinds of
data, but it delegates the actual work to various other functions dispatched
across several \R packages. See \code{getOption("read_write")}.
}
\examples{
# Use of read() as a more flexible substitute to data() (can change dataset
# name and syntax more similar to read R datasets and datasets from files)
read() # List all available datasets in your installed version of R
# List datasets in one particular package
read(package = "data.io")

# Read one dataset from this package, possibly changing its name
(urchin <- read("urchin_bio", package = "data.io"))
# Same, but using labels in French
(urchin <- read("urchin_bio", package = "data.io", lang = "fr"))
# ... and also the levels of factors in French (note: uppercase FR)
(urchin <- read("urchin_bio", package = "data.io", lang = "FR"))

# Read one dataset from another package, but with labels and comments
data(iris) # The R way: you got the initial datasets
# Same result, using read()
ir2 <- read("iris", package = "datasets", lang = NULL)
# ir2 records that it comes from datasets::iris
attr(comment(ir2), "src")
# otherwise, it is identical to iris, except is may be a data.table or a
# tibble, depending on user preferences
comment(ir2) <- NULL
# Force coercion into a data.frame
ir2 <- svBase::as_dtf(ir2)
identical(iris, ir2)
# More interesting: you can get an enhanced version of iris with read():
# (note that variable names ar in snake-case now!)
(ir3 <- read("iris", package = "datasets"))
class(ir3)
comment(ir3)
ir3$sepal_length
# ... and you can get it in French too!
(ir_fr <- read("iris", package = "datasets", lang = "fr"))
class(ir_fr)
comment(ir_fr)
ir_fr$sepal_length

# Sometimes, datasets are more deeply reworked. For instance, trees has
# variables in imperial units (in, ft, and cubic ft), but it is automatically
# reworked by read() into metric variables (m or m^3):
data(trees)
head(trees)
(trees2 <- read("trees", package = "datasets"))
comment(trees2)
trees2$volume
\donttest{
# Read from a Github Gist (need to specify the type here!)
(ble <- read$csv("http://tinyurl.com/Biostat-Ble"))

# Various versions of the famous iris dataset
(iris <- read(data_example("iris.csv")))
(iris <- read(data_example("iris.csv.zip")))
(iris <- read(data_example("iris.csv.gz")))
(iris <- read(data_example("iris.csv.bz2")))
(iris <- read(data_example("iris.tsv")))
(iris <- read(data_example("iris.xls")))
(iris <- read(data_example("iris.xlsx")))
(iris <- read(data_example("iris.rds"))) # Does not tranform into tibble!
#(iris <- read(data_example("iris.syd"))) ##
#(iris <- read(data_example("iris.csvy"))) ##
#(iris <- read(data_example("iris.csvy.zip"))) ##

# A file with an header both in English (default) and in French
(iris <- read(data_example("iris_short_header.csv")))
(iris_fr <- read(data_example("iris_short_header.csv"), lang = "fr"))
# Headers are also recognized in xls/xlsx files
(iris_fr <- read(data_example("iris_short_header.xls"), lang = "fr"))

# Read a file with a sidecar file (same name + '.R')
(iris <- read(data_example("iris_sidecar.csv"))) # lang = "en" by default
(iris <- read(data_example("iris_sidecar.csv"), lang = "EN")) # Full lang
(iris <- read(data_example("iris_sidecar.csv"), lang = "en_us")) # US (in)
(iris <- read(data_example("iris_sidecar.csv"), lang = "fr")) # French
(iris <- read(data_example("iris_sidecar.csv"), lang = "FR_BE")) # Belgian
(iris <- read(data_example("iris_sidecar.csv"), lang = NULL)) # No labels

# Require the feather package
#(iris <- read(data_example("iris.feather"))) # Not available for all Win

# Challenging datasets from the readr package
library(readr)
(mtcars <- read(readr_example("mtcars.csv")))
(mtcars <- read(readr_example("mtcars.csv.zip")))
(mtcars <- read(readr_example("mtcars.csv.bz2")))
(challenge <- read(readr_example("challenge.csv"), guess_max = 1001))
(massey <- read(readr_example("massey-rating.txt")))
# By default, the type cannot be guessed from the extension
# This is a space-separated vaules file (ssv)
(massey <- read(readr_example("massey-rating.txt"), type = "ssv"))
# or ...
(massey <- read$ssv(readr_example("massey-rating.txt")))
(epa <- read$ssv(readr_example("epa78.txt"), col_names = FALSE))
(example_log <- read(readr_example("example.log")))
# There are different ways to specify columns for fixed-width files (fwf)
# See ?read_fwf in package readr
(fwf_sample <- read$fwf(readr_example("fwf-sample.txt"),
   col_positions =  fwf_cols(name = 20, state = 10, ssn = 12)))

# Various examples of Excel datasets from readxl
library(readxl)
(xl <- read(readxl_example("datasets.xls")))
(xl <- read(readxl_example("datasets.xlsx"), sheet = "mtcars"))
(xl <- read(readxl_example("datasets.xlsx"), sheet = 3))
# Accomodate a column with disparate types via col_type = "list"
(clip <- read(readxl_example("clippy.xls"), col_types = c("text", "list")))
(clip <- read(readxl_example("clippy.xlsx"), col_types = c("text", "list")))
tibble::deframe(clip)
# Read from a specific range in a sheet
(xl <- read(readxl_example("datasets.xlsx"), range = "mtcars!B1:D5"))
(deaths <- read(readxl_example("deaths.xls"), range = cell_rows(5:15)))
(deaths <- read(readxl_example("deaths.xlsx"), range = cell_rows(5:15)))
(type_me <- read(readxl_example("type-me.xls"), sheet = "logical_coercion",
  col_types = c("logical", "text")))
(type_me <- read(readxl_example("type-me.xlsx"), sheet = "numeric_coercion",
  col_types = c("numeric", "text")))
(type_me <- read(readxl_example("type-me.xls"), sheet = "date_coercion",
  col_types = c("date", "text")))
(type_me <- read(readxl_example("type-me.xlsx"), sheet = "text_coercion",
  col_types = c("text", "text")))
(xl <- read(readxl_example("geometry.xls"), col_names = FALSE))
(xl <- read(readxl_example("geometry.xlsx"), range = cell_rows(4:8)))

# Various examples from haven
library(haven)
haven_example <- function(path)
  system.file("examples", path, package = "haven", mustWork = TRUE)
(iris2 <- read(haven_example("iris.dta"))) # Stata v. 8-14
(iris2 <- read(haven_example("iris.sav"))) # SPSS, TODO: labelled -> factor?
(pbc <- read(data_example("pbc.por"))) # SPSS, POR format
(iris2 <- read$sas(haven_example("iris.sas7bdat"))) # SAS file
(afalfa <- read(data_example("afalfa.xpt"))) # SAS transport file

# Note that where completion is available, you have a completion list of file
# format after typing read$<tab>
}
}
\seealso{
\code{\link[=data_types]{data_types()}}, \code{\link[=write]{write()}}, \code{\link[=read_csv]{read_csv()}}
}
\author{
Philippe Grosjean \href{mailto:phgrosjean@sciviews.org}{phgrosjean@sciviews.org}
}
\concept{read and import data}
\keyword{utilities}
